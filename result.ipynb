{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9ffa7a16",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "unindent does not match any outer indentation level (<tokenize>, line 55)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m<tokenize>:55\u001b[1;36m\u001b[0m\n\u001b[1;33m    engine.say('Detected pose is ' + pred)\u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mIndentationError\u001b[0m\u001b[1;31m:\u001b[0m unindent does not match any outer indentation level\n"
     ]
    }
   ],
   "source": [
    "import cv2 \n",
    "import numpy as np \n",
    "import mediapipe as mp \n",
    "from keras.models import load_model \n",
    "import pyttsx3\n",
    "\n",
    "def inFrame(lst):\n",
    "\tif lst[28].visibility > 0.6 and lst[27].visibility > 0.6 and lst[15].visibility>0.6 and lst[16].visibility>0.6:\n",
    "\t\treturn True \n",
    "\treturn False\n",
    "\n",
    "model  = load_model(\"model.h5\")\n",
    "label = np.load(\"labels.npy\")\n",
    "\n",
    "\n",
    "\n",
    "holistic = mp.solutions.pose\n",
    "holis = holistic.Pose()\n",
    "drawing = mp.solutions.drawing_utils\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "engine = pyttsx3.init()\n",
    " \n",
    "# say method on the engine that passing input text to be spoken\n",
    "engine.say('Welcome To AI Yoga pose detection')\n",
    " \n",
    "# run and wait method, it processes the voice commands. \n",
    "engine.runAndWait()\n",
    "\n",
    "while True:\n",
    "\tlst = []\n",
    "\n",
    "\t_, frm = cap.read()\n",
    "\n",
    "\twindow = np.zeros((940,940,3), dtype=\"uint8\")\n",
    "\n",
    "\tfrm = cv2.flip(frm, 1)\n",
    "\n",
    "\tres = holis.process(cv2.cvtColor(frm, cv2.COLOR_BGR2RGB))\n",
    "\n",
    "\tfrm = cv2.blur(frm, (4,4))\n",
    "\tif res.pose_landmarks and inFrame(res.pose_landmarks.landmark):\n",
    "\t\tfor i in res.pose_landmarks.landmark:\n",
    "\t\t\tlst.append(i.x - res.pose_landmarks.landmark[0].x)\n",
    "\t\t\tlst.append(i.y - res.pose_landmarks.landmark[0].y)\n",
    "\n",
    "\t\tlst = np.array(lst).reshape(1,-1)\n",
    "\n",
    "\t\tp = model.predict(lst)\n",
    "\t\tpred = label[np.argmax(p)]\n",
    "        \n",
    "\n",
    "\t\tif p[0][np.argmax(p)] > 0.75:\n",
    "\t\t\tcv2.putText(window, pred , (180,180),cv2.FONT_ITALIC, 1.3, (0,255,0),2)\n",
    "            engine.say('Detected pose is ' + pred)\n",
    "            engine.runAndWait()\n",
    "\n",
    "\t\telse:\n",
    "\t\t\tcv2.putText(window, \"Asana is either wrong not trained\" , (100,180),cv2.FONT_ITALIC, 1.8, (0,0,255),3)\n",
    "\n",
    "\telse: \n",
    "\t\tcv2.putText(frm, \"Make Sure Full body visible\", (100,450), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0,0,255),3)\n",
    "\n",
    "\t\t\n",
    "\tdrawing.draw_landmarks(frm, res.pose_landmarks, holistic.POSE_CONNECTIONS,\n",
    "\t\t\t\t\t\t\tconnection_drawing_spec=drawing.DrawingSpec(color=(255,255,255), thickness=6 ),\n",
    "\t\t\t\t\t\t\t landmark_drawing_spec=drawing.DrawingSpec(color=(0,0,255), circle_radius=3, thickness=3))\n",
    "\n",
    "\n",
    "\twindow[420:900, 170:810, :] = cv2.resize(frm, (640, 480))\n",
    "\n",
    "\tcv2.imshow(\"window\", window)\n",
    "\n",
    "\tif cv2.waitKey(1) == 27:\n",
    "\t\tcv2.destroyAllWindows()\n",
    "\t\tcap.release()\n",
    "\t\tbreak\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1c580be5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyttsx3 in c:\\users\\dell\\anaconda3\\lib\\site-packages (2.90)\n",
      "Requirement already satisfied: comtypes in c:\\users\\dell\\anaconda3\\lib\\site-packages (from pyttsx3) (1.4.0)\n",
      "Requirement already satisfied: pypiwin32 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from pyttsx3) (223)\n",
      "Requirement already satisfied: pywin32 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from pyttsx3) (305.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pyttsx3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "450885a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import mediapipe as mp\n",
    "from keras.models import load_model\n",
    "import pyttsx3\n",
    "\n",
    "def inFrame(lst):\n",
    "    if lst[28].visibility > 0.6 and lst[27].visibility > 0.6 and lst[15].visibility > 0.6 and lst[16].visibility > 0.6:\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "model = load_model(\"model.h5\")\n",
    "label = np.load(\"labels.npy\")\n",
    "\n",
    "holistic = mp.solutions.pose\n",
    "holis = holistic.Pose()\n",
    "drawing = mp.solutions.drawing_utils\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "engine = pyttsx3.init()\n",
    "\n",
    "# Voice feedback for program initiation\n",
    "engine.say('Welcome To AI Yoga pose detection')\n",
    "engine.runAndWait()\n",
    "\n",
    "while True:\n",
    "    lst = []\n",
    "\n",
    "    _, frm = cap.read()\n",
    "\n",
    "    window = np.zeros((940, 940, 3), dtype=\"uint8\")\n",
    "\n",
    "    frm = cv2.flip(frm, 1)\n",
    "\n",
    "    res = holis.process(cv2.cvtColor(frm, cv2.COLOR_BGR2RGB))\n",
    "\n",
    "    frm = cv2.blur(frm, (4, 4))\n",
    "    if res.pose_landmarks and inFrame(res.pose_landmarks.landmark):\n",
    "        for i in res.pose_landmarks.landmark:\n",
    "            lst.append(i.x - res.pose_landmarks.landmark[0].x)\n",
    "            lst.append(i.y - res.pose_landmarks.landmark[0].y)\n",
    "\n",
    "        lst = np.array(lst).reshape(1, -1)\n",
    "\n",
    "        p = model.predict(lst)\n",
    "        pred = label[np.argmax(p)]\n",
    "\n",
    "        if p[0][np.argmax(p)] > 0.75:\n",
    "            cv2.putText(window, pred, (180, 180), cv2.FONT_ITALIC, 1.3, (0, 255, 0), 2)\n",
    "            # Voice feedback for detected pose\n",
    "            engine.say('Detected pose is ' + pred)\n",
    "            engine.runAndWait()\n",
    "        else:\n",
    "            cv2.putText(window, \"Asana is either wrong or not trained\", (100, 180), cv2.FONT_ITALIC, 1.8,\n",
    "                        (0, 0, 255), 3)\n",
    "            engine.say('Asana is either wrong or not trained')\n",
    "            engine.runAndWait()\n",
    "\n",
    "    else:\n",
    "        cv2.putText(frm, \"Make Sure Full body visible\", (100, 450), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 0, 255), 3)\n",
    "         engine.say('Make Sure Full body visible')\n",
    "            engine.runAndWait()\n",
    "\n",
    "    drawing.draw_landmarks(frm, res.pose_landmarks, holistic.POSE_CONNECTIONS,\n",
    "                           connection_drawing_spec=drawing.DrawingSpec(color=(255, 255, 255), thickness=6),\n",
    "                           landmark_drawing_spec=drawing.DrawingSpec(color=(0, 0, 255), circle_radius=3,\n",
    "                                                                     thickness=3))\n",
    "\n",
    "    window[420:900, 170:810, :] = cv2.resize(frm, (640, 480))\n",
    "\n",
    "    cv2.imshow(\"window\", window)\n",
    "\n",
    "    if cv2.waitKey(1) == 27:\n",
    "        cv2.destroyAllWindows()\n",
    "        cap.release()\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1d69866",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
